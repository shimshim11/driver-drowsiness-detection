{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030dff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drive/My Drive/.csv',sep=',')\n",
    "df = df.drop(df.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage = 17/22\n",
    "train_index = int(len(df)*train_percentage)\n",
    "test_index = len(df)-train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b610942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:train_index]\n",
    "df_test = df[-test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6647ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop([\"Y\"],axis=1)\n",
    "y_test = df_test[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Y',axis=1)\n",
    "y_train = df_train['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce979037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(y_pred):\n",
    "  for i in range(len(y_pred)):\n",
    "    if i % 240 == 0 or (i+1) % 240 == 0:\n",
    "      pass\n",
    "    else: \n",
    "      average = float(y_pred[i-1] +  y_pred[i] + y_pred[i+1])/3\n",
    "      if average >= 0.5:\n",
    "        y_pred[i] = 1\n",
    "      else:\n",
    "        y_pred[i] = 0\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bce949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_1 = clf.predict(X_test)\n",
    "y_pred_1 = average(y_pred_1)\n",
    "\n",
    "y_score_1 = clf.predict_proba(X_test)[:,1]\n",
    "acc1 = accuracy_score(y_test, y_pred_1)\n",
    "f1_score_1 = metrics.f1_score(y_test, y_pred_1)\n",
    "roc_1 = metrics.roc_auc_score(y_test, y_score_1)\n",
    "\n",
    "print([acc1,f1_score_1,roc_1])\n",
    "print(confusion_matrix(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74944876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)\n",
    "\n",
    "pred_NB = clf_NB.predict(X_test)\n",
    "pred_NB = average(pred_NB)\n",
    "\n",
    "y_score_2 = clf_NB.predict_proba(X_test)[:,1]\n",
    "acc2 = accuracy_score(y_test, pred_NB)\n",
    "f1_score_2 = metrics.f1_score(y_test, pred_NB)\n",
    "roc_2 = metrics.roc_auc_score(y_test, y_score_2)\n",
    "\n",
    "print([acc2,f1_score_2,roc_2])\n",
    "print(confusion_matrix(y_test, pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ef533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "acc3_list = []\n",
    "f1_score3_list = []\n",
    "roc_3_list = []\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1,30):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(X_train, y_train) \n",
    "    pred_KN = neigh.predict(X_test)\n",
    "    pred_KN = average(pred_KN)\n",
    "    y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "    acc3_list.append(accuracy_score(y_test, pred_KN))\n",
    "    f1_score3_list.append(metrics.f1_score(y_test, pred_KN))\n",
    "    roc_3_list.append(metrics.roc_auc_score(y_test, y_score_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3_list.index(max(acc3_list))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=acc3_list.index(max(acc3_list))+1)\n",
    "neigh.fit(X_train, y_train) \n",
    "pred_KN = neigh.predict(X_test)\n",
    "pred_KN = average(pred_KN)\n",
    "y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "acc3 = accuracy_score(y_test, pred_KN)\n",
    "f1_score_3 = metrics.f1_score(y_test, pred_KN)\n",
    "roc_3 = metrics.roc_auc_score(y_test, y_score_3)\n",
    "print([acc3,f1_score_3,roc_3])\n",
    "print(confusion_matrix(y_test, pred_KN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8eff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "acc4=[]\n",
    "max_depth = []\n",
    "for i in range(1,10):\n",
    "    clf_RF = RandomForestClassifier(max_depth=i)\n",
    "    clf_RF.fit(X_train, y_train) \n",
    "    pred_RF = clf_RF.predict(X_test)\n",
    "    pred_RF = average(pred_RF)\n",
    "    acc4.append(accuracy_score(pred_RF, y_test))\n",
    "    max_depth.append(i)\n",
    "print (max(acc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_depth_4 = max_depth[acc4.index(max(acc4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(max_depth=best_depth_4)\n",
    "clf_RF.fit(X_train, y_train) \n",
    "pred_RF = clf_RF.predict(X_test)\n",
    "pred_RF = average(pred_RF)\n",
    "y_score_4 = clf_RF.predict_proba(X_test)[:,1]\n",
    "acc4 = accuracy_score(y_test, pred_RF)\n",
    "f1_score_4 = metrics.f1_score(y_test, pred_RF)\n",
    "roc_4 = metrics.roc_auc_score(y_test, y_score_4)\n",
    "print([acc4,f1_score_4,roc_4])\n",
    "print(confusion_matrix(y_test, pred_RF))\n",
    "\n",
    "feature_importances = pd.DataFrame(clf_RF.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shaped = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d20145",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shaped = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c483dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shaped.shape\n",
    "X_test_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size = 3, activation = 'relu', input_shape = (8,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.00001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_shaped, y_train, validation_data = (X_test_shaped,y_test), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c263da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "pred_cnn = model.predict_classes(X_test_shaped)\n",
    "pred_cnn = average(pred_cnn)\n",
    "y_score_5 = model.predict_proba(X_test_shaped)\n",
    "acc5 = accuracy_score(y_test, np.array(pred_cnn))\n",
    "f1_score_5 = metrics.f1_score(y_test, pred_cnn)\n",
    "roc_5 = metrics.roc_auc_score(y_test, y_score_5)\n",
    "\n",
    "print([acc5,f1_score_5,roc_5])\n",
    "print(confusion_matrix(y_test, pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_total = {'Model':['Logistic Regression','Naive Bayes', 'KNN', 'Random Forest', 'CNN',],\n",
    "        'Accuracy':[acc1,acc2, acc3, acc4, acc5]}\n",
    "accuracy_total=pd.DataFrame(accuracy_total)\n",
    "accuracy_total=accuracy_total.set_index('Model')\n",
    "accuracy_total\n",
    "plt.plot(accuracy_total['Accuracy'])\n",
    "plt.xticks(rotation=45)\n",
    "accuracy_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09050e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "fpr_1, tpr_1, thresholds = roc_curve(y_test, y_score_1)\n",
    "fpr_2, tpr_2, thresholds = roc_curve(y_test, y_score_2)\n",
    "fpr_3, tpr_3, thresholds = roc_curve(y_test, y_score_3)\n",
    "fpr_4, tpr_4, thresholds = roc_curve(y_test, y_score_4)\n",
    "fpr_5, tpr_5, thresholds = roc_curve(y_test, y_score_5)\n",
    "\n",
    "plt.plot(fpr_1, tpr_1, label= \"Logistic Regression\")\n",
    "plt.plot(fpr_2, tpr_2, label= \"Naive Bayes\")\n",
    "plt.plot(fpr_3, tpr_3, label= \"KNN\")\n",
    "plt.plot(fpr_4, tpr_4, label= \"Random Forest\")\n",
    "plt.plot(fpr_5, tpr_5, label= \"CNN\")\n",
    "\n",
    "plt.title('ROC of LSTM')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "fraction_of_positives, mean_predicted_value=calibration_curve(y_test,y_score_1,n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives,\"s-\",\n",
    "                 label=\"%s\" % 'Logistic Regression')\n",
    "\n",
    "fraction_of_positives, mean_predicted_value=calibration_curve(y_test,y_score_2,n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives,\"s-\",\n",
    "                 label=\"%s\" % 'Naive Bayes')\n",
    "\n",
    "fraction_of_positives, mean_predicted_value=calibration_curve(y_test,y_score_3,n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives,\"s-\",\n",
    "                 label=\"%s\" % 'KNN')\n",
    "\n",
    "fraction_of_positives, mean_predicted_value=calibration_curve(y_test,y_score_4,n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives,\"s-\",\n",
    "                 label=\"%s\" % 'Random Forest')\n",
    "\n",
    "fraction_of_positives, mean_predicted_value=calibration_curve(y_test,y_score_5,n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives,\"s-\",\n",
    "                 label=\"%s\" % 'CNN')\n",
    "\n",
    "plt.legend(loc=\"lower right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
